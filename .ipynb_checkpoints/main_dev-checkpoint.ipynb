{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d4d8a290-b980-4ad4-8b18-0533840c82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import MultiLineString\n",
    "from shapely import wkt\n",
    "import shapely\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import psycopg2 as psql\n",
    "from unidecode import unidecode\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "407055da-cf33-49dd-91eb-16e13f366ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "fiona.drvsupport.supported_drivers['kml'] = 'rw'  # enable KML support which is disabled by default\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'  # enable KML support which is disabled by default\n",
    "fiona.drvsupport.supported_drivers['LIBKML'] = 'rw'  # enable KML support which is disabled by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e457277f-f842-4ee7-b2cd-203f363872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\pnjoya\\Desktop\\01_IT Data\\historical_data\\tracks_archives\\africa\\diana\\w17\\W17_track_V1.0.gpx\"\n",
    "file2 = r\"C:\\Users\\pnjoya\\Desktop\\01_IT Data\\historical_data\\tracks_archives\\europe\\espana organica\\W13\\7-45-186-5-157-R1_W13.kml\"\n",
    "file3 = r\"C:\\Users\\pnjoya\\Desktop\\98_R&D\\insert_historical_data\\test_multi.kml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1488bb6-b1da-4681-b50f-bc731b7704e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GPX\n",
    "- Get GPX layers\n",
    "- Select layers to be open with Fiona\n",
    "- transform geometry into MultiLineString\n",
    "- Create DataFrame with the right format\n",
    "- Create GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f54556e7-49e2-477b-ae80-978f53eeea78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##GPX##\n",
    "\n",
    "#find the right gpx layer\n",
    "list_layers = fiona.listlayers(file)\n",
    "\n",
    "list_size_layers = list(len(list(fiona.open(file, layer = x))) for x in list_layers)\n",
    "\n",
    "min_value = min(x for x in list_size_layers if not x==0)\n",
    "\n",
    "layer_position = list_size_layers.index(min_value)\n",
    "\n",
    "layer_selected = list_layers[layer_position]\n",
    "\n",
    "#GPX to dataframe\n",
    "gps = fiona.open(file, layer = layer_selected)\n",
    "gps_list = list(gps)\n",
    "\n",
    "#Transform geometry type in MultiLineString\n",
    "for i in gps_list :\n",
    "    geom = [[]]\n",
    "    for y in i[\"geometry\"][\"coordinates\"]:\n",
    "        if isinstance(y, list):\n",
    "            for z in y:\n",
    "                point = z[:2]\n",
    "                geom[0].append(point)\n",
    "        elif isinstance(y, tuple):\n",
    "            point = y[:2]\n",
    "            geom[0].append(point)\n",
    "        else :\n",
    "            print(\"probleme here\")\n",
    "    i[\"geometry\"][\"coordinates\"] = geom\n",
    "    i[\"geometry\"][\"type\"] = 'MultiLineString'\n",
    "\n",
    "#Create dataFrame\n",
    "df = pd.DataFrame(gps_list)\n",
    "\n",
    "#Clean DataFrame\n",
    "keys = list(df.properties[0].keys())\n",
    "keys = [x.lower() for x in keys]\n",
    "values = list(df.properties[0].values())\n",
    "\n",
    "df[keys] = pd.DataFrame(df.properties.tolist(), index = df.index)\n",
    "\n",
    "\n",
    "df['num_points'] = df['geometry'].apply(lambda x: len(x['coordinates'][0])) #Get number of points per tracks\n",
    "\n",
    "df_numpoints = df.copy()[df.num_points >= 2] #Filter to have only tracks with more (or equal) than 2 points\n",
    "\n",
    "df_numpoints.geometry = df_numpoints.geometry.apply(lambda x : shape(x)) #Transform geometry dictionnary into a shapely object\n",
    "\n",
    "df_numpoints = df_numpoints[[\"id\",\"geometry\",\"name\"]]\n",
    "\n",
    "#DataFrame to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df_numpoints) #Transform DataFrame intot a GeoDataFrame\n",
    "\n",
    "gdf = gdf[[\"id\",\"geometry\",\"name\"]] #Select columns only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d29a5-922d-4fbd-8c9e-282a0c44ea90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## KML\n",
    "- Open KML file with Fiona\n",
    "- transform geometry into MultiLineString\n",
    "- Create DataFrame with the right format\n",
    "- Create GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b086a83-30cb-4ad7-a324-ecf0279a464c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##KML##\n",
    "kml = fiona.open(file2)\n",
    "kml_list = list(kml)\n",
    "\n",
    "for i in kml_list :\n",
    "    geom = [[]]\n",
    "    for y in i[\"geometry\"][\"coordinates\"]:\n",
    "        if isinstance(y, list):\n",
    "            for z in y:\n",
    "                point = z[:2]\n",
    "                geom[0].append(point)\n",
    "        elif isinstance(y, tuple):\n",
    "            point = y[:2]\n",
    "            geom[0].append(point)\n",
    "        else :\n",
    "            print(\"probleme here\")\n",
    "    i[\"geometry\"][\"coordinates\"] = geom\n",
    "    i[\"geometry\"][\"type\"] = 'MultiLineString'\n",
    "    \n",
    "df = pd.DataFrame(kml_list)\n",
    "\n",
    "#Clean DEataFrame\n",
    "keys = list(df.properties[0].keys())\n",
    "keys = [x.lower() for x in keys]\n",
    "values = list(df.properties[0].values())\n",
    "\n",
    "df[keys] = pd.DataFrame(df.properties.tolist(), index = df.index)\n",
    "\n",
    "\n",
    "df['num_points'] = df['geometry'].apply(lambda x: len(x['coordinates'][0])) #Get number of points per tracks\n",
    "\n",
    "df_numpoints = df.copy()[df.num_points >= 2] #Filter to have only tracks with more (or equal) than 2 points\n",
    "\n",
    "df_numpoints.geometry = df_numpoints.geometry.apply(lambda x : shape(x)) #Transform geometry dictionnary into a shapely object\n",
    "\n",
    "df_numpoints = df_numpoints[[\"id\",\"geometry\",\"name\"]]\n",
    "\n",
    "#DataFrame to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df_numpoints) #Transform dataFrame intot a geoDataFrame\n",
    "\n",
    "gdf = gdf[[\"id\",\"geometry\",\"name\"]] #Select columns only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f069051-806e-43c9-b09c-bded214474b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Generate variable to be inserted for one folder\n",
    "- Open a folder\n",
    "- Take every file in that folder\n",
    "- Get filename\n",
    "- Text file extension\n",
    "- Generate GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88f4efe3-91fe-4dd0-82f1-3bacbfaaf14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CABB.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-3.55241 6.11807, -3.55241 6...   \n",
      "1  1  MULTILINESTRING ((-3.55601 6.11455, -3.55606 6...   \n",
      "\n",
      "                                        name  \n",
      "0       REG__IND_W20_ABBECHOLUCIEIDA__KKO_P1  \n",
      "1  REG__IND_W20_ABBEGBOCHOFRANÇIS__KKO_P1001  \n",
      "CAG.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-7.52387 6.65433, -7.52385 6...   \n",
      "1  1  MULTILINESTRING ((-7.49715 6.73703, -7.49720 6...   \n",
      "\n",
      "                                         name  \n",
      "0     REG__GUE_W20_AHOUKOUADIOFRANCIS__KKO_P1  \n",
      "1  REG__GUE_W20_AHOUTOUKOUADIOLAURENT__KKO_P1  \n",
      "COOPADI.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-7.11889 6.93973, -7.11884 6...   \n",
      "1  1  MULTILINESTRING ((-7.07520 6.90065, -7.07529 6...   \n",
      "\n",
      "                                     name  \n",
      "0            REG__GUE_W20_AHOUYAO__KKO_P1  \n",
      "1  REG__GUE_W20_ALLAGBAKOFFIJULES__KKO_P1  \n",
      "COOPAWEB.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-7.99798 6.79126, -7.99793 6...   \n",
      "1  1  MULTILINESTRING ((-7.97712 6.76829, -7.97716 6...   \n",
      "\n",
      "                                  name  \n",
      "0  REG__CAV_W20_AROUNAOUATTARA__KKO_P1  \n",
      "1     REG__CAV_W20_BADOABOUDOU__KKO_P1  \n",
      "EDIFIE.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-5.55814 6.49512, -5.55815 6...   \n",
      "1  1  MULTILINESTRING ((-5.54167 6.51572, -5.54176 6...   \n",
      "\n",
      "                             name  \n",
      "0    REG__GO_W20_AKATOBLA__KKO_P1  \n",
      "1  REG__GO_W20_ANGOHN'DRI__KKO_P1  \n",
      "SCAEB.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-5.93778 6.72332, -5.93782 6...   \n",
      "1  1  MULTILINESTRING ((-5.93579 6.73256, -5.93570 6...   \n",
      "\n",
      "                                   name  \n",
      "0    REG__MAR_W20_BADINISIMENDE__KKO_P1  \n",
      "1  REG__MAR_W20_BATIONONBAWEMBI__KKO_P1  \n",
      "SCAEDA.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-6.29912 6.87180, -6.29914 6...   \n",
      "1  1  MULTILINESTRING ((-6.22823 6.83225, -6.22823 6...   \n",
      "\n",
      "                                 name  \n",
      "0  REG__HSAS_W20_ABOHKOUADIOSIMON___P  \n",
      "1        REG__HSAS_W20_ALLAKOFFI___P1  \n",
      "SCAPCCA.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-5.20641 6.20459, -5.20646 6...   \n",
      "1  1  MULTILINESTRING ((-5.22096 6.21894, -5.22090 6...   \n",
      "\n",
      "                                                name  \n",
      "0               REG__BEL_W20_AFFIBEDIEIGNACE__KKO_P1  \n",
      "1  REG__BEL_W20_AFFICHERBEHEGBINJEANFRANÇOIS__KKO_P1  \n",
      "SOCAAN.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-3.78394 6.09662, -3.78399 6...   \n",
      "1  1  MULTILINESTRING ((-3.86307 6.27793, -3.86307 6...   \n",
      "\n",
      "                                       name  \n",
      "0     REG__AGN_W20_ABEN'CHOCELESTIN__KKO_P1  \n",
      "1  REG__AGN_W20_ABOUDOULAYEOUATTARA__KKO_P1  \n",
      "SOCADA.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-3.71684 5.69904, -3.71680 5...   \n",
      "1  1  MULTILINESTRING ((-3.72517 5.70325, -3.72513 5...   \n",
      "\n",
      "                                  name  \n",
      "0  REG_AGN_IMMASSIBE KOMBATE SIBITI_P1  \n",
      "1      Reg_AGN_KOBENAN KRA Dit INZA_P1  \n",
      "SOCOOFEM.gpx\n",
      "  id                                           geometry  \\\n",
      "0  0  MULTILINESTRING ((-5.70397 7.08866, -5.70391 7...   \n",
      "1  1  MULTILINESTRING ((-5.66949 7.08447, -5.66954 7...   \n",
      "\n",
      "                                     name  \n",
      "0  REG__MAR_W20_AKAKOUASSIBERNARD__KKO_P1  \n",
      "1    REG__MAR_W20_AMANIKOFFIHERVE__KKO_P1  \n"
     ]
    }
   ],
   "source": [
    "folder = r\"C:\\Users\\pnjoya\\Desktop\\01_IT Data\\historical_data\\tracks_archives\\africa\\ivory coast\\W20\"\n",
    "\n",
    "for root, dirs, files in os.walk(folder) :\n",
    "    for files in os.listdir(root) :\n",
    "        filename = files\n",
    "        print(filename)\n",
    "        gpx_test = files.lower().endswith('.gpx')\n",
    "        xml_test = files.lower().endswith('.xml')\n",
    "        kml_test = files.lower().endswith('.kml')\n",
    "        file = root + \"\\\\\" + files\n",
    "        \n",
    "        if gpx_test :\n",
    "            #find the right gpx layer\n",
    "            list_layers = fiona.listlayers(file) #list all layers for GPX file\n",
    "            list_size_layers = list(len(list(fiona.open(file, layer = x))) for x in list_layers) #Get the number of elements of each layers\n",
    "            min_value = min(x for x in list_size_layers if not x==0) #Find the minimum value that is not null\n",
    "            layer_position = list_size_layers.index(min_value) #Get the the position of this minimum\n",
    "            layer_selected = list_layers[layer_position] #Get the layer that has this minimum value\n",
    "\n",
    "            #GPX to dataframe\n",
    "            geom_file = fiona.open(file, layer = layer_selected)\n",
    "        \n",
    "        elif kml_test:\n",
    "            geom_file = fiona.open(file)\n",
    "            \n",
    "        file_list = list(geom_file)\n",
    "        \n",
    "        for i in file_list :\n",
    "            geom = [[]]\n",
    "            for y in i[\"geometry\"][\"coordinates\"]:\n",
    "                if isinstance(y, list):\n",
    "                    for z in y:\n",
    "                        point = z[:2]\n",
    "                        geom[0].append(point)\n",
    "                elif isinstance(y, tuple):\n",
    "                    point = y[:2]\n",
    "                    geom[0].append(point)\n",
    "                else :\n",
    "                    print(\"probleme here\")\n",
    "            i[\"geometry\"][\"coordinates\"] = geom\n",
    "            i[\"geometry\"][\"type\"] = 'MultiLineString'\n",
    "\n",
    "        df = pd.DataFrame(file_list)\n",
    "\n",
    "        #Clean DEataFrame\n",
    "        keys = list(df.properties[0].keys())\n",
    "        keys = [x.lower() for x in keys]\n",
    "        values = list(df.properties[0].values())\n",
    "\n",
    "        df[keys] = pd.DataFrame(df.properties.tolist(), index = df.index)\n",
    "\n",
    "\n",
    "        df['num_points'] = df['geometry'].apply(lambda x: len(x['coordinates'][0])) #Get number of points per tracks\n",
    "\n",
    "        df_numpoints = df.copy()[df.num_points >= 2] #Filter to have only tracks with more (or equal) than 2 points\n",
    "\n",
    "        df_numpoints.geometry = df_numpoints.geometry.apply(lambda x : shape(x)) #Transform geometry dictionnary into a shapely object\n",
    "\n",
    "        df_numpoints = df_numpoints[[\"id\",\"geometry\",\"name\"]]\n",
    "        \n",
    "        #DataFrame to GeoDataFrame\n",
    "        gdf = gpd.GeoDataFrame(df_numpoints) #Transform dataFrame intot a geoDataFrame\n",
    "\n",
    "        gdf = gdf[[\"id\",\"geometry\",\"name\"]] #Select columns only\n",
    "        \n",
    "        #print(gdf.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ce501-da11-4f8c-a7c8-b0620d6baaca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate variable for every files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40852264-5272-41b7-b2ef-04c2dc0acd33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing africa-diana-w19: 100%|███████████████████████████████████████████████████████| 3/3 [00:00<00:00, 14.04it/s]\n",
      "Processing africa-diana-W17_track_V1.0.gpx: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 15.66it/s]\n",
      "Processing africa-diana-reg1 w18 SG (1).gpx: 100%|███████████████████████████████████████| 1/1 [00:00<00:00, 31.30it/s]\n",
      "Processing africa-diana-Tracks 2019.gpx: 100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s]\n",
      "Processing africa-ivory coast-W20: 100%|█████████████████████████████████████████████████| 2/2 [00:00<00:00, 13.71it/s]\n",
      "Processing africa-ivory coast-COOPAWEB_M1.gpx: 100%|█████████████████████████████████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "Processing africa-ivory coast-SOCOOFEM.gpx: 100%|██████████████████████████████████████| 11/11 [00:01<00:00,  6.14it/s]\n",
      "Processing africa-rwenzori-W16:  20%|██████████▍                                         | 1/5 [00:00<00:00,  9.39it/s]Exception ignored in: <function tqdm.__del__ at 0x0000016E6FC78CA0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pnjoya\\anaconda3\\envs\\insert_historical_data\\lib\\site-packages\\tqdm\\std.py\", line 1162, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\pnjoya\\anaconda3\\envs\\insert_historical_data\\lib\\site-packages\\tqdm\\std.py\", line 1281, in close\n",
      "    if self.disable:\n",
      "AttributeError: 'tqdm' object has no attribute 'disable'\n",
      "Processing africa-rwenzori-W19: 100%|████████████████████████████████████████████████████| 5/5 [00:00<00:00,  8.04it/s]\n",
      "Processing africa-rwenzori-W1_RFCU_3.0.gpx: 100%|████████████████████████████████████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Processing africa-rwenzori-W2_RFCU_1.0.gpx: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "Processing africa-rwenzori-Tracks_Reg_Uganda_W3_ALL.gpx: 100%|███████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "Processing africa-rwenzori-W18_ALL.gpx: 100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Processing africa-rwenzori-RFCU-W19-M1-GPS_Tracks_Final.gpx: 100%|███████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Processing africa-sidama-SI-ET_W20_v0.8_WIP.gpx: 100%|███████████████████████████████████| 4/4 [00:09<00:00,  2.31s/it]\n",
      "Processing asia & pacific-alter trade-W17: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  2.07it/s]\n",
      "Processing asia & pacific-alter trade-00_HH Ph wave 3B (checked by DJ).gpx: 100%|████████| 1/1 [00:00<00:00, 12.04it/s]\n",
      "Processing asia & pacific-alter trade-00_HH Ph wave 3B (checked by DJ) (1).gpx: 100%|████| 1/1 [00:00<00:00, 12.15it/s]\n",
      "Processing asia & pacific-darjeeling-Track_YANGKHOO.gpx: 100%|█████████████████████████| 91/91 [00:01<00:00, 47.42it/s]\n",
      "Processing asia & pacific-kbqb-Wave4_154 tracks_complete2.gpx: 100%|█████████████████████| 6/6 [00:01<00:00,  3.76it/s]\n",
      "Processing europe-espana organica-W20: 100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 13.78it/s]\n",
      "Processing europe-espana organica-7-45-186-68-118_W13.kml: 100%|███████████████████████| 12/12 [00:00<00:00, 44.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probleme here\n",
      "REGION :  europe  - PROJECT : espana organica  - FILE:  7-45-186-33-36-R2_W13.kml\n",
      "<class 'float'>\n",
      "{'type': 'Feature', 'id': '1', 'properties': OrderedDict([('Name', 'MCarmen Simón'), ('description', None), ('timestamp', None), ('begin', None), ('end', None), ('altitudeMode', None), ('tessellate', -1), ('extrude', 0), ('visibility', -1), ('drawOrder', None), ('icon', None)]), 'geometry': {'type': 'Point', 'coordinates': (-3.334361263686655, 39.53387968000843, 0.0)}}\n",
      "probleme here\n",
      "REGION :  europe  - PROJECT : espana organica  - FILE:  7-45-186-33-36-R2_W13.kml\n",
      "<class 'float'>\n",
      "{'type': 'Feature', 'id': '1', 'properties': OrderedDict([('Name', 'MCarmen Simón'), ('description', None), ('timestamp', None), ('begin', None), ('end', None), ('altitudeMode', None), ('tessellate', -1), ('extrude', 0), ('visibility', -1), ('drawOrder', None), ('icon', None)]), 'geometry': {'type': 'Point', 'coordinates': (-3.334361263686655, 39.53387968000843, 0.0)}}\n",
      "probleme here\n",
      "REGION :  europe  - PROJECT : espana organica  - FILE:  7-45-186-33-36-R2_W13.kml\n",
      "<class 'float'>\n",
      "{'type': 'Feature', 'id': '1', 'properties': OrderedDict([('Name', 'MCarmen Simón'), ('description', None), ('timestamp', None), ('begin', None), ('end', None), ('altitudeMode', None), ('tessellate', -1), ('extrude', 0), ('visibility', -1), ('drawOrder', None), ('icon', None)]), 'geometry': {'type': 'Point', 'coordinates': (-3.334361263686655, 39.53387968000843, 0.0)}}\n",
      "probleme here\n",
      "REGION :  europe  - PROJECT : espana organica  - FILE:  7-45-186-33-36-R4_W13.kml\n",
      "<class 'float'>\n",
      "{'type': 'Feature', 'id': '1', 'properties': OrderedDict([('Name', 'MCarmen Simón'), ('description', None), ('timestamp', None), ('begin', None), ('end', None), ('altitudeMode', None), ('tessellate', -1), ('extrude', 0), ('visibility', -1), ('drawOrder', None), ('icon', None)]), 'geometry': {'type': 'Point', 'coordinates': (-3.334361263686655, 39.53387968000843, 0.0)}}\n",
      "probleme here\n",
      "REGION :  europe  - PROJECT : espana organica  - FILE:  7-45-186-33-36-R4_W13.kml\n",
      "<class 'float'>\n",
      "{'type': 'Feature', 'id': '1', 'properties': OrderedDict([('Name', 'MCarmen Simón'), ('description', None), ('timestamp', None), ('begin', None), ('end', None), ('altitudeMode', None), ('tessellate', -1), ('extrude', 0), ('visibility', -1), ('drawOrder', None), ('icon', None)]), 'geometry': {'type': 'Point', 'coordinates': (-3.334361263686655, 39.53387968000843, 0.0)}}\n",
      "probleme here\n",
      "REGION :  europe  - PROJECT : espana organica  - FILE:  7-45-186-33-36-R4_W13.kml\n",
      "<class 'float'>\n",
      "{'type': 'Feature', 'id': '1', 'properties': OrderedDict([('Name', 'MCarmen Simón'), ('description', None), ('timestamp', None), ('begin', None), ('end', None), ('altitudeMode', None), ('tessellate', -1), ('extrude', 0), ('visibility', -1), ('drawOrder', None), ('icon', None)]), 'geometry': {'type': 'Point', 'coordinates': (-3.334361263686655, 39.53387968000843, 0.0)}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing europe-espana organica-7-45-85-28-109.kml: 100%|████████████████████████████| 36/36 [00:00<00:00, 80.74it/s]\n",
      "Processing europe-espana organica-PARCELAS_ACCOR_VALENCIA.kml: 100%|█████████████████████| 2/2 [00:00<00:00, 35.16it/s]\n",
      "Processing europe-espana organica-espana_organica_w16.kml: 100%|█████████████████████████| 1/1 [00:00<00:00, 26.32it/s]\n",
      "Processing europe-espana organica-Registros FGN 2017.kml: 100%|██████████████████████████| 1/1 [00:00<00:00, 41.72it/s]\n",
      "Processing europe-espana organica-NA_2018_7-45-88-16-5-R1.kml: 100%|███████████████████| 50/50 [00:00<00:00, 91.44it/s]\n",
      "Processing europe-espana organica-Annex 7 FGlobalNature_2019.kml: 100%|██████████████████| 1/1 [00:00<00:00, 38.42it/s]\n",
      "Processing europe-espana organica-FGlobalNature_july_2020.kml: 100%|█████████████████████| 2/2 [00:00<00:00, 41.01it/s]\n",
      "Processing europe-mihai eminescu trust-W20: 100%|████████████████████████████████████████| 8/8 [00:00<00:00, 55.71it/s]\n",
      "Processing europe-mihai eminescu trust-SA Proforest Atid V 79C.KML: 100%|████████████| 135/135 [00:01<00:00, 75.13it/s]\n",
      "Processing europe-mihai eminescu trust-Malin.kml: 100%|████████████████████████████████| 23/23 [00:01<00:00, 19.57it/s]\n",
      "Processing europe-mihai eminescu trust-Composesotatul Mujna -143E.KML: 100%|███████████| 14/14 [00:00<00:00, 82.78it/s]\n",
      "Processing europe-mihai eminescu trust-Victoria.kml: 100%|█████████████████████████████| 15/15 [00:00<00:00, 76.71it/s]\n",
      "Processing europe-mihai eminescu trust-Prim. Rem. 82A.kml: 100%|███████████████████████| 27/27 [00:00<00:00, 80.63it/s]\n",
      "Processing europe-mihai eminescu trust-Primaria Tg. Secuiesc X 109G_OSP Mereni.kml: 100%|█| 23/23 [00:00<00:00, 66.88it\n",
      "Processing europe-mihai eminescu trust-UAT Galatii Bistritei_na_OS Valea Sieului.kml: 100%|█| 25/25 [00:00<00:00, 81.78\n",
      "Processing europe-mihai eminescu trust-364_UAT Sohodol_5A.9A_OS Abrud.kml: 100%|███████| 22/22 [00:00<00:00, 57.69it/s]\n",
      "Processing latin america-aprosacao-Planting Wave2019.gpx: 100%|██████████████████████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Processing latin america-frajianes-Tracks_Pre-registro2015_LB 2.gpx: 100%|█████████████| 21/21 [00:05<00:00,  3.64it/s]\n",
      "Processing latin america-la giorgia-R&M1_PAS_14102020.gpx: 100%|█████████████████████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Processing latin america-pintze-Track_M01_Ola7_2020.gpx: 100%|███████████████████████████| 4/4 [00:04<00:00,  1.23s/it]\n",
      "Processing latin america-jubilacion segura-Oro Verde: 100%|██████████████████████████████| 7/7 [00:00<00:00,  7.36it/s]\n",
      "Processing latin america-jubilacion segura-Track_JS 2019.gpx: 100%|██████████████████████| 5/5 [00:00<00:00,  6.27it/s]\n",
      "Processing latin america-jubilacion segura-TRACK Y WAYPOINTS - AFOTUR OLA N° 03 (2016).gpx: 100%|█| 4/4 [00:00<00:00, 3\n",
      "Processing latin america-jubilacion segura-TRACK WAYPOINTS (PUNTOS) - 34 - APROCOYCE  AMAZONAS - OLA N° 2017 - ( WCHJ).\n",
      "Processing latin america-jubilacion segura-TRACKS OLA N°4 2017-COOPARM.gpx: 100%|████████| 4/4 [00:00<00:00, 13.01it/s]\n",
      "Processing latin america-jubilacion segura-TRANCK + CODIGOS OLA 2.gpx: 100%|█████████████| 7/7 [00:00<00:00, 14.23it/s]\n",
      "Processing latin america-jubilacion segura-TRACKS MON 1 OLA 9-2019.gpx: 100%|██████████| 12/12 [00:01<00:00,  9.57it/s]\n",
      "Processing latin america-jubilacion segura-ORO VERDE JS- OLA 9-2016- Completo.gpx: 100%|█| 6/6 [00:10<00:00,  1.78s/it]\n",
      "Processing latin america-alto huayabamba-AH- Base tracks.gpx: 100%|██████████████████████| 1/1 [00:03<00:00,  3.86s/it]\n",
      "Processing latin america-cfp-_layer_Tracks_CFP_W2019_Monitoring1_ 852, tracks.gpx: 100%|█| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Processing latin america-narino-_layer_NARIÑO_Pre-registro_Ola 7 (2020), tracks.gpx: 100%|█| 6/6 [00:04<00:00,  1.48it/\n",
      "Processing latin america-cauca-_layer_PRE-2020-CAUCA, tracks.gpx: 100%|██████████████████| 7/7 [00:06<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "dictprojet = {\n",
    "        \"africa\" : [\"diana\",\"ivory coast\",\"rwenzori\",\"sidama\"],\n",
    "        \"asia & pacific\" : [\"alter trade\",\"darjeeling\",\"kbqb\"],\n",
    "        \"europe\" : [\"espana organica\",\"mihai eminescu trust\"],\n",
    "        \"latin america\" : [\"aprosacao\",\"frajianes\",\"la giorgia\",\"pintze\",\"jubilacion segura\",\"alto huayabamba\",\"cfp\",\"narino\",\"cauca\"]\n",
    "    }\n",
    "\n",
    "for region in list(dictprojet) :\n",
    "    for project in dictprojet[region] :\n",
    "        dir = \"C:/Users/pnjoya/Desktop/01_IT Data/historical_data/tracks/\"\n",
    "        dir_archives = \"C:/Users/pnjoya/Desktop/01_IT Data/historical_data/tracks_archives/\"\n",
    "        dir_archives = dir_archives+region+'/'+project+'/'\n",
    "\n",
    "        for root, dirs, files in os.walk(dir_archives) :\n",
    "            pbar = tqdm(os.listdir(root))\n",
    "            for files in pbar :\n",
    "                pbar.set_description(f'Processing {region}-{project}-{files}')\n",
    "                filename = files\n",
    "                add_date = datetime.date.today()\n",
    "                #print(\"REGION : \", region, \" - PROJECT :\", project, \" - FILE: \", files)\n",
    "                gpx_test = files.lower().endswith('.gpx')\n",
    "                xml_test = files.lower().endswith('.xml')\n",
    "                kml_test = files.lower().endswith('.kml')\n",
    "                file = root + \"/\" + files\n",
    "\n",
    "                if gpx_test :\n",
    "                    #find the right gpx layer\n",
    "                    #list_layers = fiona.listlayers(file) #list all layers for GPX file\n",
    "                    list_layers = ['routes', 'tracks']\n",
    "                    list_size_layers = list(len(list(fiona.open(file, layer = x))) for x in list_layers) #Get the number of elements of each layers\n",
    "                    #print(list_size_layers)\n",
    "                    min_value = min(x for x in list_size_layers if not x==0) #Find the minimum value that is not null\n",
    "                    layer_position = list_size_layers.index(min_value) #Get the the position of this minimum\n",
    "                    layer_selected = list_layers[layer_position] #Get the layer that has this minimum value\n",
    "                    \n",
    "                    #print(layer_selected)\n",
    "\n",
    "                    #GPX to dataframe\n",
    "                    geom_file = fiona.open(file, layer = layer_selected)\n",
    "\n",
    "                elif kml_test:\n",
    "                    geom_file = fiona.open(file)\n",
    "                    \n",
    "                if 'geom_file' in locals():\n",
    "\n",
    "                    file_list = list(geom_file)\n",
    "                    file_json = json.dumps(file_list, ensure_ascii=False)\n",
    "\n",
    "                    for i in file_list :\n",
    "                        geom = [[]]\n",
    "                        for y in i[\"geometry\"][\"coordinates\"]:\n",
    "                            if isinstance(y, list):\n",
    "                                for z in y:\n",
    "                                    if isinstance(z, list):\n",
    "                                        for zz in z:\n",
    "                                            point = zz[:2]\n",
    "                                            geom[0].append(point)\n",
    "                                    else :\n",
    "                                        point = z[:2]\n",
    "                                        geom[0].append(point)\n",
    "                            elif isinstance(y, tuple):\n",
    "                                point = y[:2]\n",
    "                                geom[0].append(point)\n",
    "                            else :\n",
    "                                print(\"probleme here\")\n",
    "                                print(\"REGION : \", region, \" - PROJECT :\", project, \" - FILE: \", files)\n",
    "                                print(type(y))\n",
    "                                print(i)\n",
    "                                \n",
    "                        i[\"geometry\"][\"coordinates\"] = geom\n",
    "                        i[\"geometry\"][\"type\"] = 'MultiLineString'\n",
    "\n",
    "                    df = pd.DataFrame(file_list)\n",
    "\n",
    "                    #Clean DEataFrame\n",
    "                    keys = list(df.properties[0].keys())\n",
    "                    keys = [x.lower() for x in keys]\n",
    "                    values = list(df.properties[0].values())\n",
    "\n",
    "                    df[keys] = pd.DataFrame(df.properties.tolist(), index = df.index)\n",
    "\n",
    "\n",
    "                    df['num_points'] = df['geometry'].apply(lambda x: len(x['coordinates'][0])) #Get number of points per tracks\n",
    "\n",
    "                    df_numpoints = df.copy()[df.num_points >= 2] #Filter to have only tracks with more (or equal) than 2 points\n",
    "\n",
    "                    df_numpoints.geometry = df_numpoints.geometry.apply(lambda x : shape(x)) #Transform geometry dictionnary into a shapely object\n",
    "\n",
    "                    df_numpoints = df_numpoints[[\"id\",\"geometry\",\"name\"]] #Select columns only\n",
    "\n",
    "                    #DataFrame to GeoDataFrame\n",
    "                    gdf = gpd.GeoDataFrame(df_numpoints) #Transform dataFrame intot a geoDataFrame\n",
    "\n",
    "                    #print(gdf.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f352dd-1708-4b1b-a2c8-4dca3e63f347",
   "metadata": {},
   "source": [
    "## Generate DataFrame from Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cabfc0a7-4ac2-486d-885b-22b0821f1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQLAlchemy engine\n",
    "engine = create_engine('postgresql+psycopg2://pp_fabien:9N9GNK78TyXQtls6@db01.postgres.database.azure.com/fielddata_dev', client_encoding='utf8') #add client_encoding='utf8'\n",
    "\n",
    "# Connect to PostgreSQL server\n",
    "dbConnection    = engine.connect()\n",
    "\n",
    "# Connect to PostgreSQL server with psql\n",
    "conn = psql.connect(host=\"db01.postgres.database.azure.com\", dbname=\"fielddata_dev\", user=\"pp_fabien\", password=\"9N9GNK78TyXQtls6\")\n",
    "conn.set_client_encoding('utf-8')\n",
    "    \n",
    "# Define SQL Query\n",
    "project_query = \"SELECT * FROM \\\"HistoricalData\\\".projects\"\n",
    "parcelwave_query = \"SELECT id, lower(replace(replace(replace(gpsfilename, '_',''),' ',''),'-','')) as gpsfilename FROM \\\"HistoricalData\\\".parcelwaves\"\n",
    "\n",
    "gpsextfiles_query = \"SELECT filejson FROM \\\"HistoricalData\\\".gpsextfiles as g1\\\n",
    "                    join \\\"HistoricalData\\\".projects p on g1.projectid = p.id\"\n",
    "gpsexttracks_query = \"SELECT gpsname, gps FROM\\\n",
    "                    \\\"HistoricalData\\\".gpsexttracks as g\\\n",
    "                    join \\\"HistoricalData\\\".gpsextfiles as g1 on g.fileid = g1.id\\\n",
    "                    join \\\"HistoricalData\\\".projects p on g1.projectid = p.id\"\n",
    "\n",
    "# Create a gdf from postgis view\n",
    "df_project = pd.read_sql(project_query, dbConnection)\n",
    "df_parcelwave = pd.read_sql(parcelwave_query, dbConnection)\n",
    "df_gpsextfiles = pd.read_sql(gpsextfiles_query, dbConnection)\n",
    "df_gpsexttracks = pd.read_sql(gpsexttracks_query, dbConnection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "124ea8aa-9783-44be-8e2c-53bb1c856d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQLAlchemy engine\n",
    "engine = create_engine('postgresql+psycopg2://ppadmin:$Colombia2021@db01.postgres.database.azure.com/fielddata', client_encoding='utf8') #add client_encoding='utf8'\n",
    "\n",
    "# Connect to PostgreSQL server\n",
    "dbConnection    = engine.connect()\n",
    "\n",
    "# Connect to PostgreSQL server with psql\n",
    "conn = psql.connect(host=\"db01.postgres.database.azure.com\", dbname=\"fielddata\", user=\"ppadmin\", password=\"$Colombia2021\")\n",
    "conn.set_client_encoding('utf-8')\n",
    "    \n",
    "# Define SQL Query\n",
    "project_query = \"SELECT * FROM projects\"\n",
    "parcelwave_query = \"SELECT id, lower(replace(replace(replace(parcelname, '_',''),' ',''),'-','')) as parcelname FROM parcelwaves\"\n",
    "\n",
    "gpsextfiles_query = \"SELECT filejson FROM gpsextfiles as g1\\\n",
    "                    join projects p on g1.projectid = p.id\"\n",
    "gpsexttracks_query = \"SELECT gpsname, gps FROM\\\n",
    "                    gpsexttracks as g\\\n",
    "                    join gpsextfiles as g1 on g.fileid = g1.id\\\n",
    "                    join projects p on g1.projectid = p.id\"\n",
    "\n",
    "# Create a gdf from postgis view\n",
    "df_project = pd.read_sql(project_query, dbConnection)\n",
    "df_parcelwave = pd.read_sql(parcelwave_query, dbConnection)\n",
    "df_gpsextfiles = pd.read_sql(gpsextfiles_query, dbConnection)\n",
    "df_gpsexttracks = pd.read_sql(gpsexttracks_query, dbConnection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "292ede44-35ab-4a93-8db9-7383c47ddba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>regionid</th>\n",
       "      <th>projectname</th>\n",
       "      <th>projectdevname</th>\n",
       "      <th>projectcountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A Tree for a Child</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SOS Sahel</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Kuapa Kokoo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Khaithal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PUR Hexagone - Forests</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  regionid             projectname projectdevname projectcountry\n",
       "0   7       1.0      A Tree for a Child           None           None\n",
       "1   9       1.0               SOS Sahel           None           None\n",
       "2  11       1.0             Kuapa Kokoo           None           None\n",
       "3  12       1.0                Khaithal           None           None\n",
       "4  13       1.0  PUR Hexagone - Forests           None           None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_project.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb8d300f-106e-4cd4-8a19-21ac810409f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parcelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20586</td>\n",
       "      <td>prew22piragua4934633m1perennialp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18848</td>\n",
       "      <td>kinonecooperative|kitholhu|biirajovia|m2b|p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20582</td>\n",
       "      <td>prew22pandeazucar11517911m2afallowsp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25145</td>\n",
       "      <td>acopagrobasemariscalcaceresodiliapiscosatalyam3p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24002</td>\n",
       "      <td>alietgreen|kulonprogo|subiyartowahyuno|m2a|p1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                         parcelname\n",
       "0  20586                  prew22piragua4934633m1perennialp1\n",
       "1  18848       kinonecooperative|kitholhu|biirajovia|m2b|p1\n",
       "2  20582              prew22pandeazucar11517911m2afallowsp1\n",
       "3  25145  acopagrobasemariscalcaceresodiliapiscosatalyam3p1\n",
       "4  24002      alietgreen|kulonprogo|subiyartowahyuno|m2a|p1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parcelwave.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6437343-8401-4894-85e3-8ec6b10e406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnjoya\\Documents\\GitHub\\insert_historical_data\n"
     ]
    }
   ],
   "source": [
    "df_parcelwave.to_csv(\"test_df_parcelwave.csv\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d7cdc13-7a4a-40a8-a67c-bd2fe9d06638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filejson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filejson]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpsextfiles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ebef944-3c2f-4760-8615-58c97e092439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpsname</th>\n",
       "      <th>gps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gpsname, gps]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpsexttracks.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f1f2d-4805-4bab-bd55-4960b0cab185",
   "metadata": {},
   "source": [
    "## Compare data from file to DataFrames from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f1244e6b-af25-48f8-91a6-5263d5148d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asia & pacific-Nescafe China-asia & pacific: 100%|██████████████████████████| 1/1 [00:00<00:00, 1003.18it/s]\n",
      "Processing asia & pacific-Nescafe China-Nescafe China: 100%|████████████████████████████| 1/1 [00:00<00:00, 497.84it/s]\n",
      "Processing asia & pacific-Nescafe China-Pre_reg_China_Nescafe_Pu'er_W2022.kml: 100%|█████| 1/1 [00:00<00:00,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already in DB\n",
      "Pre_reg_China_Nescafe_Pu'er_W2022.kml  has been moved to archives\n",
      "end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dictprojet_historicaldata = {\n",
    "        \"africa\" : [\"diana\",\"ivory coast\",\"rwenzori\",\"sidama\"],\n",
    "        \"asia & pacific\" : [\"alter trade\",\"darjeeling\",\"kbqb\"],\n",
    "        \"europe\" : [\"espana organica\",\"mihai eminescu trust\"],\n",
    "        \"latin america\" : [\"aprosacao\",\"frajianes\",\"la giorgia\",\"pintze\",\"jubilacion segura\",\"alto huayabamba\",\"cfp\",\"narino\",\"cauca\"]\n",
    "    }\n",
    "\n",
    "dictprojet_prod = {\n",
    "        \"asia & pacific\" : [\"Nescafe China\"]\n",
    "        }\n",
    "\n",
    "#requêtes d'insertion\n",
    "cur_insert_file = conn.cursor()\n",
    "cur_insert_track = conn.cursor()\n",
    "cur_insert_geom = conn.cursor()\n",
    "q_insert_file = \"INSERT INTO \\\"HistoricalData\\\".gpsextfiles(projectid, name, filejson, dateinsert) VALUES (%s, %s, %s, %s) RETURNING id;\"\n",
    "q_insert_track = \"INSERT INTO \\\"HistoricalData\\\".gpsexttracks(fileid, trackid, gpsname, gps) VALUES (%s, %s, %s, %s) RETURNING id;\"\n",
    "q_insert_geom = \"INSERT INTO \\\"HistoricalData\\\".gps(parcelwaveid, gpsexttrackid, isgpsodk, geom) VALUES (%s, %s, %s, %s);\".replace(\"'NULL'\",\"NULL\")\n",
    "\n",
    "q_insert_file_prod = \"INSERT INTO gpsextfiles(projectid, name, filejson, dateinsert) VALUES (%s, %s, %s, %s) RETURNING id;\"\n",
    "q_insert_track_prod = \"INSERT INTO gpsexttracks(fileid, trackid, gpsname, gps) VALUES (%s, %s, %s, %s) RETURNING id;\"\n",
    "q_insert_geom_prod = \"INSERT INTO gps(parcelwaveid, gpsexttrackid, isgpsodk, geom) VALUES (%s, %s, %s, %s);\".replace(\"'NULL'\",\"NULL\")\n",
    "\n",
    "#for region in list(dictprojet_historicaldata) :\n",
    "#    for project in dictprojet_historicaldata[region] :\n",
    "#        dir_historicaldata = \"C:/Users/pnjoya/Desktop/01_IT Data/historical_data/tracks/\"\n",
    "#        dir_archives_historicaldata = \"C:/Users/pnjoya/Desktop/01_IT Data/historical_data/tracks_archives/\"\n",
    "#        dir_archives_historicaldata = dir_archives_historicaldata+region+'/'+project+'/'\n",
    "        \n",
    "for region in list(dictprojet_prod) :\n",
    "    for project in dictprojet_prod[region] :\n",
    "        dir_prod = \"C:/Users/pnjoya/Desktop/01_IT Data/insert_tracks/tracks/\"\n",
    "        dir_archives_prod = \"C:/Users/pnjoya/Desktop/01_IT Data/insert_tracks/tracks_archives/\"\n",
    "        dir_archives_prod = dir_archives_prod+region+'/'+project+'/'\n",
    "        \n",
    "        projectid = df_project[df_project.projectname == project][\"id\"].iloc[0] #PROJECTID\n",
    "        print(type(int(projectid)))\n",
    "        projectid = int(projectid)\n",
    "\n",
    "        for root, dirs, files in os.walk(dir_prod) :\n",
    "            pbar = tqdm(os.listdir(root))\n",
    "            for files in pbar :\n",
    "                pbar.set_description(f'Processing {region}-{project}-{files}')\n",
    "                \n",
    "                filename = files #FILENAME\n",
    "                \n",
    "                add_date = datetime.date.today() #DATEINSERT\n",
    "                \n",
    "                #print(\"REGION : \", region, \" - PROJECT :\", project, \" - FILE: \", files)\n",
    "                gpx_test = files.lower().endswith('.gpx')\n",
    "                xml_test = files.lower().endswith('.xml')\n",
    "                kml_test = files.lower().endswith('.kml')\n",
    "                file = root + \"/\" + files\n",
    "\n",
    "                if gpx_test :\n",
    "                    #find the right gpx layer\n",
    "                    #list_layers = fiona.listlayers(file) #list all layers for GPX file\n",
    "                    list_layers = ['routes', 'tracks']\n",
    "                    list_size_layers = list(len(list(fiona.open(file, layer = x))) for x in list_layers) #Get the number of elements of each layers\n",
    "                    #print(list_size_layers)\n",
    "                    min_value = min(x for x in list_size_layers if not x==0) #Find the minimum value that is not null\n",
    "                    layer_position = list_size_layers.index(min_value) #Get the the position of this minimum\n",
    "                    layer_selected = list_layers[layer_position] #Get the layer that has this minimum value\n",
    "                    \n",
    "                    #print(layer_selected)\n",
    "\n",
    "                    #GPX to dataframe\n",
    "                    geom_file = fiona.open(file, layer = layer_selected)\n",
    "                    \n",
    "                    \n",
    "                elif kml_test:\n",
    "                    geom_file = fiona.open(file)\n",
    "                    \n",
    "                    \n",
    "                #if 'geom_file' in locals():\n",
    "                if gpx_test or kml_test :\n",
    "                    \n",
    "                    file_list = list(geom_file)\n",
    "                    \n",
    "                    file_json = json.dumps(list(geom_file), ensure_ascii=False) #FILEJSON\n",
    "                    \n",
    "                    if df_gpsextfiles[df_gpsextfiles.filejson == file_json].empty :\n",
    "                        \n",
    "                        cur_insert_file.execute(q_insert_file_prod, (projectid, filename, file_json, add_date))\n",
    "                        \n",
    "                        id_file = cur_insert_file.fetchone()[0] #FILEID\n",
    "\n",
    "                        for i in file_list :\n",
    "                            geom = [[]]\n",
    "                            for coordinates in i[\"geometry\"][\"coordinates\"]:\n",
    "                                if isinstance(coordinates, list):\n",
    "                                    for points in coordinates:\n",
    "                                        if isinstance(points, list):\n",
    "                                            for point in points:\n",
    "                                                latlong = point[:2]\n",
    "                                                geom[0].append(latlong)\n",
    "                                        else :\n",
    "                                            latlong = points[:2]\n",
    "                                            geom[0].append(latlong)\n",
    "                                elif isinstance(coordinates, tuple):\n",
    "                                    latlong = coordinates[:2]\n",
    "                                    geom[0].append(latlong)\n",
    "                                else :\n",
    "                                    print(\"probleme here\")\n",
    "                                    print(\"REGION : \", region, \" - PROJECT :\", project, \" - FILE: \", files)\n",
    "                                    print(type(y))\n",
    "                                    print(i)\n",
    "\n",
    "                            i[\"geometry\"][\"coordinates\"] = geom\n",
    "                            i[\"geometry\"][\"type\"] = 'MultiLineString'\n",
    "\n",
    "                        df = pd.DataFrame(file_list)\n",
    "\n",
    "                        #Clean DEataFrame\n",
    "                        keys = list(df.properties[0].keys())\n",
    "                        keys = [x.lower() for x in keys]\n",
    "                        values = list(df.properties[0].values())\n",
    "\n",
    "                        df[keys] = pd.DataFrame(df.properties.tolist(), index = df.index)\n",
    "\n",
    "\n",
    "                        df['num_points'] = df['geometry'].apply(lambda x: len(x['coordinates'][0])) #Get number of points per tracks\n",
    "\n",
    "                        df_numpoints = df.copy()[df.num_points >= 2] #Filter to have only tracks with more (or equal) than 2 points\n",
    "\n",
    "                        df_numpoints.geometry = df_numpoints.geometry.apply(lambda x : shape(x)) #Transform geometry dictionnary into a shapely object\n",
    "\n",
    "                        df_numpoints = df_numpoints[[\"id\",\"geometry\",\"name\"]] #Select columns only\n",
    "\n",
    "                        #DataFrame to GeoDataFrame\n",
    "                        gdf = gpd.GeoDataFrame(df_numpoints) #Transform dataFrame intot a geoDataFrame\n",
    "                        \n",
    "                        for row in range(0, gdf.shape[0]) :\n",
    "                            #print(row)\n",
    "                            \n",
    "                            tracknb = row #TRACKID\n",
    "                            \n",
    "                            trackname = gdf.iloc[row][\"name\"] \n",
    "                            trackname_check = unidecode(trackname) #TRACKNAME\n",
    "                             \n",
    "                            \n",
    "                            gps = str(gdf.iloc[row][\"geometry\"]) #GEOM\n",
    "                            if df_gpsexttracks[(df_gpsexttracks.gpsname == trackname_check)&(df_gpsexttracks.gps == gps)].empty :\n",
    "                                \n",
    "                                cur_insert_track.execute(q_insert_track_prod, (id_file, tracknb, trackname_check.replace(\"'\",\"\"), gps))\n",
    "                            \n",
    "                                gpsextractid = cur_insert_track.fetchone()[0] ###GPS - gpsextrractid###\n",
    "                                gpsextractid = int(gpsextractid)\n",
    "                                isgpsodk = False\n",
    "                                \n",
    "                                trackname_clean = trackname_check.lower().replace('_','').replace(' ','').replace('-','')\n",
    "                                parcelwave = df_parcelwave[df_parcelwave[\"parcelname\"] == trackname_clean] #PARCELWAVEID\n",
    "                                if parcelwave.empty :\n",
    "                                    parcelwaveid = None\n",
    "                                else :\n",
    "                                    parcelwaveid = parcelwave['id'].iloc[0]\n",
    "                                    parcelwaveid = int(parcelwaveid)\n",
    "                                \n",
    "                                cur_insert_geom.execute(q_insert_geom_prod, (parcelwaveid, gpsextractid, isgpsodk, gps))\n",
    "                            else :\n",
    "                                print(\"tracks already in DB\")\n",
    "                                conn.rollback()\n",
    "                    else :\n",
    "                        print(\"File already in DB\")\n",
    "                        conn.rollback()\n",
    "                        \n",
    "                    geom_file.close()\n",
    "                    root_archives = root.replace('tracks','tracks_archives')\n",
    "                    os.makedirs(root_archives, exist_ok=True)\n",
    "                    shutil.move(root + '/' + files, root_archives+'/'+files) #Archivage du fichier\n",
    "                    print(files, \" has been moved to archives\")\n",
    "                    \n",
    "                            \n",
    "                            \n",
    "                        \n",
    "                        #print(gdf)\n",
    "                       \n",
    "            \n",
    "        \n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c8749749-539a-434f-b05d-caff5c4f4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "92d04dce-3bb3-4ffe-a5c3-d0c7a08ed2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(conn):\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5315b47-5541-453a-9db5-762168724b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
